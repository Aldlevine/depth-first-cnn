{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 4.55%\n",
      "Close 96.12%\n",
      "MaxDiff 0.000640869140625\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, overload\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from utils.size import Size2_t, Size2_p, to_size\n",
    "\n",
    "\n",
    "def conv2d_b(\n",
    "    inp: Tensor,\n",
    "    weight: Tensor,\n",
    "    dilation: Size2_p = 1,\n",
    "    padding: Size2_p = 0,\n",
    "    stride: Size2_p = 1,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Shape:\n",
    "        inp: (*, InC, H, W)\n",
    "        weight: (OutC, InC, KH, KW)\n",
    "    \"\"\"\n",
    "    assert weight.dim() == 4\n",
    "    kernel_size = weight.shape[-2:]\n",
    "    dilation = to_size(2, dilation)\n",
    "    padding = to_size(2, padding)\n",
    "    stride = to_size(2, stride)\n",
    "\n",
    "    blocks = F.unfold(inp, kernel_size, dilation, padding, stride).transpose(-2, -1)\n",
    "    weight = weight.view(weight.shape[0], -1).t()\n",
    "    out = blocks @ weight\n",
    "\n",
    "    h_out = (\n",
    "        inp.shape[-2] + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1\n",
    "    ) // stride[0] + 1\n",
    "    w_out = (\n",
    "        inp.shape[-1] + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1\n",
    "    ) // stride[1] + 1\n",
    "    out = out.transpose(-2, -1).view(inp.shape[0], weight.shape[1], h_out, w_out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def conv2d_d(\n",
    "    inp: Tensor,\n",
    "    weight: Tensor,\n",
    "    dilation: Size2_p = 1,\n",
    "    padding: Size2_p = 0,\n",
    "    stride: Size2_p = 1,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Shape:\n",
    "        inp: (*, InC, H, W)\n",
    "        weight: (OutC, InC, KH, KW)\n",
    "    \"\"\"\n",
    "    assert weight.dim() == 4\n",
    "    kernel_size = weight.shape[-2:]\n",
    "    dilation = to_size(2, dilation)\n",
    "    padding = to_size(2, padding)\n",
    "    stride = to_size(2, stride)\n",
    "\n",
    "    blocks = F.unfold(inp, kernel_size, dilation, padding, stride).transpose(-2, -1)\n",
    "    weight = weight.view(weight.shape[0], -1).t()\n",
    "\n",
    "    out_stack: list[Tensor] = []\n",
    "    for i in range(blocks.shape[-2]):\n",
    "        i_blocks = blocks[..., i : i + 1, :]\n",
    "        i_out = i_blocks @ weight\n",
    "        out_stack.append(i_out)\n",
    "    out = torch.cat(out_stack, dim=-2)\n",
    "\n",
    "    h_out = (\n",
    "        inp.shape[-2] + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1\n",
    "    ) // stride[0] + 1\n",
    "    w_out = (\n",
    "        inp.shape[-1] + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1\n",
    "    ) // stride[1] + 1\n",
    "    out = out.transpose(-2, -1).view(inp.shape[0], weight.shape[1], h_out, w_out)\n",
    "    return out\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float32\n",
    "inp = torch.randn(1, 16, 16, 16, dtype=dtype, device=device)\n",
    "\n",
    "w1 = torch.randn(32, 16, 3, 3, dtype=dtype, device=device)\n",
    "w2 = torch.randn(64, 32, 3, 3, dtype=dtype, device=device)\n",
    "w3 = torch.randn(64, 64, 3, 3, dtype=dtype, device=device)\n",
    "w4 = torch.randn(64, 64, 3, 3, dtype=dtype, device=device)\n",
    "w5 = torch.randn(64, 64, 3, 3, dtype=dtype, device=device)\n",
    "\n",
    "nn.init.kaiming_normal_(w1)\n",
    "nn.init.kaiming_normal_(w2)\n",
    "nn.init.kaiming_normal_(w3)\n",
    "nn.init.kaiming_normal_(w4)\n",
    "nn.init.kaiming_normal_(w5)\n",
    "\n",
    "b = inp\n",
    "b = conv2d_b(b, w1, padding=1)\n",
    "b = conv2d_b(b, w2, padding=1)\n",
    "b = conv2d_b(b, w3, padding=1)\n",
    "b = conv2d_b(b, w4, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "b = conv2d_b(b, w5, padding=1)\n",
    "\n",
    "d = inp\n",
    "d = conv2d_d(d, w1, padding=1)\n",
    "d = conv2d_d(d, w2, padding=1)\n",
    "d = conv2d_d(d, w3, padding=1)\n",
    "d = conv2d_d(d, w4, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "d = conv2d_d(d, w5, padding=1)\n",
    "\n",
    "equal = (b == d).count_nonzero().item() / b.numel() * 100\n",
    "close = torch.isclose(b, d).count_nonzero().item() / b.numel() * 100\n",
    "print(f\"Equal {equal:.2f}%\")\n",
    "print(f\"Close {close:.2f}%\")\n",
    "print(\"MaxDiff\", (b - d).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 100.00%\n",
      "Close 100.00%\n",
      "MaxDiff 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "dtype = torch.float16\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# define the tensors for matrix multiplication\n",
    "batch_size = 1\n",
    "input_dim = 64\n",
    "hidden_dim = 512\n",
    "\n",
    "x = torch.randn(batch_size, input_dim, hidden_dim, dtype=dtype, device=device)\n",
    "y = torch.randn(batch_size, hidden_dim, input_dim, dtype=dtype, device=device)\n",
    "\n",
    "# perform batch matrix multiplication using torch.bmm()\n",
    "output = torch.bmm(x, y)\n",
    "\n",
    "# verify determinism\n",
    "output2 = torch.bmm(x[..., :1, :], y)\n",
    "\n",
    "b, d = output[..., 0, :], output2[..., 0, :]\n",
    "equal = (b == d).count_nonzero().item() / b.numel() * 100\n",
    "close = torch.isclose(b, d).count_nonzero().item() / b.numel() * 100\n",
    "print(f\"Equal {equal:.2f}%\")\n",
    "print(f\"Close {close:.2f}%\")\n",
    "print(\"MaxDiff\", (b - d).abs().max().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
