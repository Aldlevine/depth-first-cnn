{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, overload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from modules.df_conv2d import conv2d_b, conv2d_d\n",
    "from utils.debug import print_diff\n",
    "from utils.functions import stable_softmax\n",
    "from utils.size import Size2_p, Size2_t, to_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 80.24%\n",
      "Close 97.50%\n",
      "MaxDiff 1.68e-03\n",
      "A:\n",
      "    Range [-4.29e+01, 4.26e+01]\n",
      "    Mean -9.45e-04\n",
      "    Std 8.50e+00\n",
      "B:\n",
      "    Range [-4.29e+01, 4.26e+01]\n",
      "    Mean -9.45e-04\n",
      "    Std 8.50e+00    \n"
     ]
    }
   ],
   "source": [
    "def get_mask(attn: Tensor) -> Tensor:\n",
    "    mask = torch.ones(attn.shape[-2:], device=attn.device, dtype=attn.dtype).tril(0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def attention_b(\n",
    "    inp: Tensor,\n",
    "    v_size: int,\n",
    "    k_size: int,\n",
    "    weight: Tensor,\n",
    ") -> Tensor:\n",
    "    *b, c, h, w = inp.shape\n",
    "    assert weight.shape == (2 * k_size + v_size, c, 1, 1)\n",
    "    qkv = conv2d_b(inp, weight)\n",
    "    q, k, v = (\n",
    "        t.view(*b, -1, h * w)\n",
    "        for t in torch.split_with_sizes(qkv, [k_size, k_size, v_size], -3)\n",
    "    )\n",
    "\n",
    "    attn = q.transpose(-2, -1) @ k\n",
    "    mask = get_mask(attn)\n",
    "    attn = attn + mask.where(mask == 0, -torch.inf)\n",
    "    attn = stable_softmax(attn, -2).nan_to_num()\n",
    "    attn = attn.triu(1)\n",
    "\n",
    "    out = v @ attn\n",
    "    return out.view(*b, v_size, h, w)\n",
    "\n",
    "\n",
    "def attention_d(\n",
    "    inp: Tensor,\n",
    "    v_size: int,\n",
    "    k_size: int,\n",
    "    weight: Tensor,\n",
    ") -> Tensor:\n",
    "    *b, c, h, w = inp.shape\n",
    "    assert weight.shape == (2 * k_size + v_size, c, 1, 1)\n",
    "    out = torch.zeros(*b, v_size, h, w)\n",
    "    qkv = torch.zeros(*b, 2 * k_size + v_size, h, w)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            qkv[..., y, x] = conv2d_d(inp, weight, pos=(y, x)).squeeze()\n",
    "            q, k, v = (\n",
    "                t.view(*b, -1, h * w)\n",
    "                for t in torch.split_with_sizes(qkv, [k_size, k_size, v_size], -3)\n",
    "            )\n",
    "            i = y * w + x\n",
    "            q = q[..., :i]\n",
    "            k = k[..., i : i + 1]\n",
    "            v = v[..., :i]\n",
    "            attn = q.transpose(-2, -1) @ k\n",
    "            attn = stable_softmax(attn, -3).nan_to_num()\n",
    "            out[..., y, x] = (v @ attn).squeeze()\n",
    "    return out\n",
    "\n",
    "\n",
    "inp = torch.randn(64, 64, 28, 28)\n",
    "weight = torch.randn(8 + 8 + 64, 64, 1, 1)\n",
    "ab = attention_b(inp, 64, 8, weight)\n",
    "ad = attention_d(inp, 64, 8, weight)\n",
    "print_diff(ab, ad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 10.00%\n",
      "Close 98.95%\n",
      "MaxDiff 5.7220458984375e-05\n",
      "A:\n",
      "    Range: [-7.59e+01, 7.46e+01]\n",
      "    Mean: -2.49e-02\n",
      "    Std: 1.60e+01\n",
      "B:\n",
      "    Range: [-7.59e+01, 7.46e+01]\n",
      "    Mean: -2.49e-02\n",
      "    Std: 1.60e+01\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(256, 32, 256, device=\"cuda\")\n",
    "b = torch.randn(256, 256, 64, device=\"cuda\")\n",
    "\n",
    "c1 = a @ b\n",
    "c2 = torch.stack([a[:, i:i+1, :] @ b for i in range(a.shape[1])], dim=1).squeeze()\n",
    "\n",
    "print_diff(c1, c2)\n",
    "# torch.allclose(c1, c2)\n",
    "# torch.equal(c1, c2)\n",
    "# equal = ((c1 == c2).count_nonzero() / c1.numel()).item() * 100\n",
    "# close = (torch.isclose(c1, c2).count_nonzero() / c1.numel()).item() * 100\n",
    "# maxdiff = (c1 - c2).abs().max().item()\n",
    "# print(f\"Equal {equal:.2f}%\")\n",
    "# print(f\"Close {close:.2f}%\")\n",
    "# print(f\"MaxDiff {maxdiff:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
